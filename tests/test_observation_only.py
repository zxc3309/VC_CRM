#!/usr/bin/env python3
"""
å°ˆé–€æ¸¬è©¦ Observation å’Œ Questions ç”¢ç”Ÿçš„ç°¡åŒ–æ¸¬è©¦
ä¸ä¾è³´ Google APIï¼Œåªæ¸¬è©¦æ ¸å¿ƒé‚è¼¯
"""
import asyncio
import json
import logging
import sys
import os

# æ·»åŠ  VC_CRM ç›®éŒ„åˆ°è·¯å¾‘
sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'VC_CRM'))

from dotenv import load_dotenv
from openai import AsyncOpenAI
from prompt_manager import GoogleSheetPromptManager

# è¨­ç½®æ—¥èªŒ
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class TestDocManager:
    """ç°¡åŒ–çš„ DocManager é¡åˆ¥ï¼Œå°ˆé–€æ¸¬è©¦ suggest_questions_with_gpt"""
    
    def __init__(self):
        load_dotenv(override=True)
        self.openai_client = AsyncOpenAI(api_key=os.getenv("OPENAI_API_KEY"))
        self.prompt_manager = GoogleSheetPromptManager()
    
    def format_questions(self, questions):
        """å°‡å•é¡Œåˆ—è¡¨æ ¼å¼åŒ–ç‚ºæ•¸å­—åˆ—é»å½¢å¼"""
        formatted = []
        for i, question in enumerate(questions, 1):
            if isinstance(question, str):
                formatted.append(f"{i}. {question}")
            elif isinstance(question, dict):
                for key, value in question.items():
                    formatted.append(f"{i}. {key}: {value}")
        return "\n".join(formatted)
    
    def format_observation(self, observation):
        """å°‡è§€å¯Ÿåˆ—è¡¨æ ¼å¼åŒ–ç‚ºæ•¸å­—åˆ—é»å½¢å¼"""
        if not isinstance(observation, list):
            return str(observation)
        formatted = []
        for i, obs in enumerate(observation, 1):
            if isinstance(obs, str):
                formatted.append(f"{i}. {obs}")
            elif isinstance(obs, dict):
                formatted.append(f"{i}. " + ", ".join(f"{k}: {v}" for k, v in obs.items()))
            else:
                formatted.append(f"{i}. {str(obs)}")
        return "\n".join(formatted)
    
    async def suggest_questions_with_gpt(self, deal_data, input_data):
        """æ ¹æ“š pitch deck æ‘˜è¦ï¼Œè‡ªå‹•å»ºè­°ç¬¬ä¸€æ¬¡æ¥è§¸è©²æ–°å‰µæ‡‰è©²å•çš„å•é¡Œ"""
        try:
            # å¾ prompt manager ç²å–å•é¡Œåˆ—è¡¨
            question_list1 = self.prompt_manager.get_prompt('question_list1')
            question_list2 = self.prompt_manager.get_prompt('question_list2')
            question_list3 = self.prompt_manager.get_prompt('question_list3')
            question_list4 = self.prompt_manager.get_prompt('question_list4')

            # ä½¿ç”¨ GoogleSheetPromptManager ç²å–æç¤ºè©
            prompt = self.prompt_manager.get_prompt_and_format(
                'suggest_questions',
                deal_data=json.dumps(deal_data, ensure_ascii=False),
                question_list1=question_list1,
                question_list2=question_list2,
                question_list3=question_list3,
                question_list4=question_list4
            )

            # å–å¾— AI model
            ai_model = input_data.get('ai_model') or "gpt-4o-mini"  # ä½¿ç”¨ä¾¿å®œçš„æ¨¡å‹æ¸¬è©¦

            response = await self.openai_client.chat.completions.create(
                model=ai_model,
                messages=[
                    {"role": "system", "content": "You are a professional VC analyst."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.7,
                response_format={"type": "json_object"}
            )

            result = response.choices[0].message.content
            logger.info(f"[suggest_questions] AI åŸå§‹å›æ‡‰é•·åº¦: {len(result)} å­—ç¬¦")
            logger.info(f"[suggest_questions] AI åŸå§‹å›æ‡‰å…§å®¹: {result[:500]}...")
            
            # åˆå§‹åŒ– result_jsonï¼Œé¿å…å¾ŒçºŒå¼•ç”¨éŒ¯èª¤
            result_json = {}
            
            try:
                result_json = json.loads(result)
                logger.info(f"[suggest_questions] æˆåŠŸè§£æ JSONï¼ŒåŒ…å«æ¬„ä½: {list(result_json.keys())}")
                
                questions = result_json.get("questions", [])
                observation = result_json.get("observation", [])
                
                logger.info(f"[suggest_questions] æå–åˆ° {len(questions)} å€‹å•é¡Œ")
                logger.info(f"[suggest_questions] æå–åˆ° {len(observation)} å€‹è§€å¯Ÿ")
                
                if not questions:
                    logger.warning("[suggest_questions] âš ï¸ æœªæ‰¾åˆ° 'questions' æ¬„ä½æˆ–æ¬„ä½ç‚ºç©º")
                if not observation:
                    logger.warning("[suggest_questions] âš ï¸ æœªæ‰¾åˆ° 'observation' æ¬„ä½æˆ–æ¬„ä½ç‚ºç©º")
                    
            except Exception as e:
                questions = []
                observation = []
                # è§£æå¤±æ•—æ™‚ï¼Œè¨­ç½®ç©ºçš„ result_json
                result_json = {"questions": [], "observation": [], "error": str(e)}
                logger.error(f"[suggest_questions] âŒ è§£æ AI å›å‚³å•é¡Œ/è§€å¯Ÿæ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{str(e)}")
                logger.error(f"[suggest_questions] AI è¿”å›å…§å®¹: {result[:200]}...")

            # æ–°å¢ï¼šæŠŠ prompt å’Œçµæœæ”¾åˆ° input_data
            input_data["AI Prompt5"] = prompt
            input_data["AI Content5"] = json.dumps(result_json, ensure_ascii=False)

            return questions, observation
        except Exception as e:
            logger.error(f"ç”Ÿæˆå•é¡Œæ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{str(e)}")
            return [], []

async def test_observation_and_questions():
    """å°ˆé–€æ¸¬è©¦ observation å’Œ questions çš„ç”¢ç”Ÿ"""
    
    print("=" * 80)
    print("ğŸ§ª æ¸¬è©¦ Observation å’Œ Questions ç”¢ç”Ÿ")
    print("=" * 80)
    
    # æ¸¬è©¦æ•¸æ“š
    test_deal_data = {
        "company_name": "TrueNorth",
        "founder_name": ["Willy", "Alex"],
        "company_info": {
            "company_introduction": "Crypto's first AI discovery engine using agentic technology to unlock a symbiotic user journey - from intent straight to outcome"
        },
        "founder_info": {
            "title": "Co-founders",
            "background": "Serial entrepreneur, Forbes 30 Under 30, PhD in AI",
            "previous_companies": "WOO, McKinsey, Temasek, Enflame, Iluvatar",
            "education": "PhD in AI & Domain-Specific Computing",
            "achievements": "Successful M&A exit, Forbes 30 Under 30"
        },
        "funding_info": "Backed by Cyber Fund, Delphi Labs and founders, GPs from Layerzero, Virtuals, SEI",
        "company_category": "AI/Crypto"
    }
    
    test_input_data = {
        "ai_model": "gpt-4o-mini",
        "search_model": "gpt-4o-mini"
    }
    
    try:
        print("ğŸ”§ åˆå§‹åŒ–æ¸¬è©¦çµ„ä»¶...")
        doc_manager = TestDocManager()
        print("âœ… åˆå§‹åŒ–å®Œæˆ")
        
        print("\nğŸ¤– é–‹å§‹ç”¢ç”Ÿ Observation å’Œ Questions...")
        questions, observations = await doc_manager.suggest_questions_with_gpt(
            test_deal_data, 
            test_input_data
        )
        
        print(f"\nğŸ“Š çµæœçµ±è¨ˆ:")
        print(f"  - Questions: {len(questions)} å€‹")
        print(f"  - Observations: {len(observations)} å€‹")
        
        if questions:
            print("\nâœ… Questions æˆåŠŸç”¢ç”Ÿ!")
            print("ğŸ¤” å•é¡Œå…§å®¹:")
            for i, q in enumerate(questions, 1):
                print(f"  {i}. {q}")
        else:
            print("\nâŒ Questions æœªç”¢ç”Ÿ")
            
        if observations:
            print("\nâœ… Observations æˆåŠŸç”¢ç”Ÿ!")
            print("ğŸ‘ï¸ è§€å¯Ÿå…§å®¹:")
            for i, obs in enumerate(observations, 1):
                print(f"  {i}. {obs}")
        else:
            print("\nâŒ Observations æœªç”¢ç”Ÿ")
        
        # æ¸¬è©¦æ ¼å¼åŒ–åŠŸèƒ½
        if questions or observations:
            print("\nğŸ¨ æ¸¬è©¦æ ¼å¼åŒ–åŠŸèƒ½...")
            formatted_questions = doc_manager.format_questions(questions)
            formatted_observations = doc_manager.format_observation(observations)
            
            print("\nğŸ“‹ æ ¼å¼åŒ–å¾Œçš„ Questions:")
            print(formatted_questions)
            
            print("\nğŸ‘ï¸ æ ¼å¼åŒ–å¾Œçš„ Observations:")  
            print(formatted_observations)
        
        # æª¢æŸ¥å„²å­˜çš„å…§å®¹
        ai_content5 = test_input_data.get("AI Content5", "")
        if ai_content5:
            print(f"\nğŸ’¾ AI Content5 å·²å„²å­˜ï¼Œé•·åº¦: {len(ai_content5)} å­—ç¬¦")
            try:
                saved_data = json.loads(ai_content5)
                print(f"ğŸ“¦ å„²å­˜çš„æ¬„ä½: {list(saved_data.keys())}")
            except:
                print("âš ï¸ å„²å­˜çš„å…§å®¹ç„¡æ³•è§£æç‚º JSON")
        
        # æœ€çµ‚çµæœ
        print("\n" + "=" * 80)
        if questions and observations:
            print("ğŸ‰ æ¸¬è©¦æˆåŠŸï¼Observation å’Œ Questions éƒ½å·²æ­£ç¢ºç”¢ç”Ÿ")
            print("âœ… åœ¨å¯¦éš›çš„ Google Doc ä¸­æ‡‰è©²æœƒçœ‹åˆ°é€™äº›å…§å®¹")
        elif questions or observations:
            print("âš ï¸ æ¸¬è©¦éƒ¨åˆ†æˆåŠŸï¼Œä½†æœ‰äº›å…§å®¹æœªç”¢ç”Ÿ")
        else:
            print("âŒ æ¸¬è©¦å¤±æ•—ï¼Œæœªç”¢ç”Ÿä»»ä½• Observation æˆ– Questions")
        print("=" * 80)
        
    except Exception as e:
        print(f"\nâŒ æ¸¬è©¦éç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    asyncio.run(test_observation_and_questions())